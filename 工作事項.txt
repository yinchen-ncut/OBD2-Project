yinchen-ncut



把256*256的影像讀進來，切成4096*16的矩陣，要排成這樣的原因是要餵給神經網路去做訓練，那他會根據net和歸屬函數矩陣去跑，最後會得到分群的結果，這裡分成64群，最後把群中心找出來那個就是codebook

//35:20


Vector Quantization

33

假設我用256*256的影像，我現在要用神經網路來做分類，我要分類之前，我先把原影像做切割，這裡假設是4*4的不重覆的區塊，切成4096*16的矩陣，那這一行我們在這把它稱為是一個vector，總共有4096行，那接下來要做壓縮我就必需把資料量reduce下來，所以我選擇失真壓縮技術vq，那我論文不是用傳統的vq，我是使用fuzzy霍普神經網路來做，我將他用來訓練編碼簿，因為編碼簿訓練出來後，可以用這個編碼簿的index來去重建影像達到壓縮的目的，


我就是用這個神經網路的結構來做訓練，我把4096個vector，直列這裡是剛剛切的4096的vector，那codebook size我可以自已決定要訓練多大，我可以選擇64、128或256，一般來說效果都還不錯，那假設我要分為64群，那我的神經元就是4096*64，而且每個神經元都是完全連接的，這個神經網路就是可以拿來做分群的效果，因為我4096個向量要分成64群一定要用學習的方式分成64種最佳的結果，

那這是我的訓練的公式，然後我會maintain一個membership function，我就是使用這個公式net去調整它的權重，那我會有一個歸屬函數矩陣U，那這個z就是訓練樣本，那這個就是群中心，那它就是我們的訓練樣本要和群中心去算距離當成他的net，因為訓練過程是用最鄰近法則，愈接近的就會成為一群，所以透過調整net才知道是哪一群，這裡u矩陣會是4096訓練樣本*64類，那在這迭代過程裡面，利用演算法的net和歸屬函數矩陣就可以達到分群的目的，迭代的過程穩定後，就是訓練出來的誤差都小於我設定的門檻，就是分群完畢，那分群完後，我把每一群的群中心算出來，最後得到新的codebook

我們看到這張圖，剛剛的做法為什麼這樣做可以達到壓縮的目的，因為我們原本的codebook有4096*16，經訓練完後我們的codebook只有64*16，那經由通訊的角度來說，兩個目的，一個是減少儲存容量，或是增加通訊上的傳輸速度，所以這邊input vector就是我的影像，然後我要重建影像只需要找index就可以了，按照鄰近法則來作，就用4096*16這個矩陣和經訓練過後的64*16的新的codebook去找歐基里德最近的距離，








